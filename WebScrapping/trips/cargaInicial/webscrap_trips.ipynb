{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "from google.oauth2 import service_account\n",
    "import psutil\n",
    "import pyarrow.parquet as pq\n",
    "import io\n",
    "\n",
    "# Ruta al archivo JSON de las credenciales\n",
    "key_path = '/Users/negro/Library/CloudStorage/OneDrive-Personal/Documentos/00 Fran/01 - Personales/02-Learn/0. Data Science/0. Data Science/2_projects/1_final/ML/nyc-taxis-and-carbon-emission-3a54f163fa47.json'\n",
    "\n",
    "# Cargar las credenciales desde el archivo JSON\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "\n",
    "# Crear un cliente de BigQuery utilizando las credenciales cargadas\n",
    "client = bigquery.Client(credentials=credentials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genera los enlaces de los archivos Parquet para todos los años y meses faltantes desde year_month hasta la fecha actual\n",
    "enlaces_parquet = []\n",
    "\n",
    "# Obtener fecha de ejecución\n",
    "fecha_actual = datetime.now()\n",
    "fecha_actual_str = fecha_actual.strftime('%Y-%m')\n",
    "\n",
    "# Obtener fecha más actual de tabla trips\n",
    "query = '''\n",
    "    SELECT MAX(time_id) AS max_time_id\n",
    "    FROM `trip_records_clean.allTrips_2018_2023`\n",
    "'''\n",
    "query_job = client.query(query)\n",
    "result = query_job.result()\n",
    "row = next(result)\n",
    "\n",
    "# Obtiene la fecha más actual\n",
    "max_time_id = row['max_time_id']\n",
    "fecha_tabla = max_time_id.strftime('%Y-%m')\n",
    "\n",
    "while fecha_tabla <= fecha_actual_str:\n",
    "    yellow_tripdata_url = f'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{fecha_tabla}.parquet'\n",
    "    green_tripdata_url = f'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_{fecha_tabla}.parquet'\n",
    "\n",
    "    enlaces_parquet.append(yellow_tripdata_url)\n",
    "    enlaces_parquet.append(green_tripdata_url)\n",
    "\n",
    "    fecha_tabla = (datetime.strptime(fecha_tabla, '%Y-%m') + pd.DateOffset(months=1)).strftime('%Y-%m')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificar contenido archivos parquet\n",
    "def verificar_parquet_file(parquet_url):\n",
    "    # Verificar si el enlace contiene un archivo Parquet válido\n",
    "    try:\n",
    "        response = requests.head(parquet_url)\n",
    "        if response.status_code == 200 and response.headers.get('content-type') == 'application/octet-stream':\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except requests.exceptions.RequestException:\n",
    "        return False\n",
    "\n",
    "# Lista para almacenar los DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Procesar cada enlace de archivo Parquet\n",
    "for parquet_url in enlaces_parquet:\n",
    "    # Verificar si el enlace contiene un archivo Parquet\n",
    "    if verificar_parquet_file(parquet_url):\n",
    "        # Descargar el archivo Parquet\n",
    "        response = requests.get('parquet_url')\n",
    "        parquet_content = response.content\n",
    "        df = pd.read_parquet(parquet_content, engine='pyarrow')\n",
    "\n",
    "        # Agregar el DataFrame a la lista\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenar los DataFrames en uno solo\n",
    "df_concatenated = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2022-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-07.parquet']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enlaces_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet')\n",
    "parquet_content = response.content\n",
    "df = pd.read_parquet(parquet_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet')\n",
    "parquet_content = response.content\n",
    "columnas = ['pickup_datetime', 'dropoff_datetime', 'passenger_count', 'trip_distance', 'payment_type', 'pickup_location_id', 'dropoff_location_id', 'total_amount' , 'tip_amount']\n",
    "df = pd.read_parquet(parquet_content, engine='auto',columns=columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/negro/Downloads/yellow_tripdata_2023-01.parquet'\n",
    "columnas = ['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', 'payment_type', 'PULocationID', 'DOLocationID','payment_type', 'total_amount' , 'tip_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(path, engine='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "def read_parquet_with_schema(path, schema):\n",
    "    # Leer el archivo Parquet con el esquema especificado\n",
    "    table = pq.read_table(path, columns=list(schema.keys()))\n",
    "\n",
    "    # Obtener los datos del archivo Parquet según el esquema\n",
    "    data = {}\n",
    "    for attr, attr_schema in schema.items():\n",
    "        column_data = table.column(attr).to_pandas()\n",
    "        if attr_schema['dtype'] is not None:\n",
    "            column_data = column_data.astype(attr_schema['dtype'])\n",
    "            if np.issubdtype(attr_schema['dtype'], np.integer):\n",
    "                column_data = column_data.replace([np.inf, -np.inf], np.nan).dropna().astype(attr_schema['dtype'])\n",
    "        data[attr_schema['name']] = column_data\n",
    "\n",
    "    # Crear el DataFrame con los datos del archivo Parquet y el esquema deseado\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Ruta del archivo Parquet\n",
    "path = '/Users/negro/Downloads/yellow_tripdata_2023-01.parquet'\n",
    "\n",
    "# Esquema deseado para la lectura del archivo Parquet\n",
    "schema = {\n",
    "    'tpep_pickup_datetime': {'name': 'pickup_datetime', 'dtype': 'datetime64[ns]'},\n",
    "    'tpep_dropoff_datetime': {'name': 'dropoff_datetime', 'dtype': 'datetime64[ns]'},\n",
    "    'passenger_count': {'name': 'passenger_count', 'dtype': float},\n",
    "    'trip_distance': {'name': 'distance', 'dtype': float},\n",
    "    'payment_type': {'name': 'payment_type', 'dtype': str},\n",
    "    'PULocationID': {'name': 'pickup_location', 'dtype': float},\n",
    "    'DOLocationID': {'name': 'dropoff_location', 'dtype': float},\n",
    "    'total_amount': {'name': 'total_amount', 'dtype': float},\n",
    "    'tip_amount': {'name': 'tip_amount', 'dtype': float}\n",
    "}\n",
    "\n",
    "# Leer el archivo Parquet con el esquema deseado\n",
    "df = read_parquet_with_schema(path, schema)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>distance</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>pickup_location</th>\n",
       "      <th>dropoff_location</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>tip_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 00:32:10</td>\n",
       "      <td>2023-01-01 00:40:36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2</td>\n",
       "      <td>161.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>14.30</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 00:55:08</td>\n",
       "      <td>2023-01-01 01:01:27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>16.90</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 00:25:04</td>\n",
       "      <td>2023-01-01 00:37:49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>34.90</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01 00:03:48</td>\n",
       "      <td>2023-01-01 00:13:25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>138.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.85</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01 00:10:29</td>\n",
       "      <td>2023-01-01 00:21:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1</td>\n",
       "      <td>107.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>19.68</td>\n",
       "      <td>3.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pickup_datetime    dropoff_datetime  passenger_count  distance  \\\n",
       "0 2023-01-01 00:32:10 2023-01-01 00:40:36              1.0      0.97   \n",
       "1 2023-01-01 00:55:08 2023-01-01 01:01:27              1.0      1.10   \n",
       "2 2023-01-01 00:25:04 2023-01-01 00:37:49              1.0      2.51   \n",
       "3 2023-01-01 00:03:48 2023-01-01 00:13:25              0.0      1.90   \n",
       "4 2023-01-01 00:10:29 2023-01-01 00:21:19              1.0      1.43   \n",
       "\n",
       "  payment_type  pickup_location  dropoff_location  total_amount  tip_amount  \n",
       "0            2            161.0             141.0         14.30        0.00  \n",
       "1            1             43.0             237.0         16.90        4.00  \n",
       "2            1             48.0             238.0         34.90       15.00  \n",
       "3            1            138.0               7.0         20.85        0.00  \n",
       "4            1            107.0              79.0         19.68        3.28  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "DefaultCredentialsError",
     "evalue": "Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDefaultCredentialsError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 80\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39m# Descarga los archivos Parquet al bucket en Google Cloud Storage\u001b[39;00m\n\u001b[1;32m     79\u001b[0m bucket_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mweb_scraping_trips_0\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> 80\u001b[0m download_parquet_files(links, bucket_name)\n\u001b[1;32m     82\u001b[0m \u001b[39m# Lee los archivos Parquet y crea el DataFrame con el esquema deseado\u001b[39;00m\n\u001b[1;32m     83\u001b[0m df \u001b[39m=\u001b[39m read_parquet_files_with_schema(links, schema)\n",
      "Cell \u001b[0;32mIn[25], line 7\u001b[0m, in \u001b[0;36mdownload_parquet_files\u001b[0;34m(links, bucket_name)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdownload_parquet_files\u001b[39m(links, bucket_name):\n\u001b[1;32m      6\u001b[0m     \u001b[39m# Crea una instancia del cliente de almacenamiento de Google Cloud\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     storage_client \u001b[39m=\u001b[39m storage\u001b[39m.\u001b[39;49mClient()\n\u001b[1;32m      9\u001b[0m     \u001b[39m# Recorre la lista de enlaces para descargar los archivos Parquet\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[39mfor\u001b[39;00m link \u001b[39min\u001b[39;00m links:\n\u001b[1;32m     11\u001b[0m         \u001b[39m# Obtiene el nombre del archivo Parquet del enlace\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/cloud/storage/client.py:173\u001b[0m, in \u001b[0;36mClient.__init__\u001b[0;34m(self, project, credentials, _http, client_info, client_options, use_auth_w_custom_endpoint)\u001b[0m\n\u001b[1;32m    170\u001b[0m             no_project \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    171\u001b[0m             project \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m<none>\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 173\u001b[0m \u001b[39msuper\u001b[39;49m(Client, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    174\u001b[0m     project\u001b[39m=\u001b[39;49mproject,\n\u001b[1;32m    175\u001b[0m     credentials\u001b[39m=\u001b[39;49mcredentials,\n\u001b[1;32m    176\u001b[0m     client_options\u001b[39m=\u001b[39;49mclient_options,\n\u001b[1;32m    177\u001b[0m     _http\u001b[39m=\u001b[39;49m_http,\n\u001b[1;32m    178\u001b[0m )\n\u001b[1;32m    180\u001b[0m \u001b[39mif\u001b[39;00m no_project:\n\u001b[1;32m    181\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproject \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/cloud/client/__init__.py:320\u001b[0m, in \u001b[0;36mClientWithProject.__init__\u001b[0;34m(self, project, credentials, client_options, _http)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, project\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, credentials\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, client_options\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, _http\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 320\u001b[0m     _ClientProjectMixin\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39mself\u001b[39;49m, project\u001b[39m=\u001b[39;49mproject, credentials\u001b[39m=\u001b[39;49mcredentials)\n\u001b[1;32m    321\u001b[0m     Client\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[1;32m    322\u001b[0m         \u001b[39mself\u001b[39m, credentials\u001b[39m=\u001b[39mcredentials, client_options\u001b[39m=\u001b[39mclient_options, _http\u001b[39m=\u001b[39m_http\n\u001b[1;32m    323\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/cloud/client/__init__.py:268\u001b[0m, in \u001b[0;36m_ClientProjectMixin.__init__\u001b[0;34m(self, project, credentials)\u001b[0m\n\u001b[1;32m    265\u001b[0m     project \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(credentials, \u001b[39m\"\u001b[39m\u001b[39mproject_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    267\u001b[0m \u001b[39mif\u001b[39;00m project \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 268\u001b[0m     project \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_determine_default(project)\n\u001b[1;32m    270\u001b[0m \u001b[39mif\u001b[39;00m project \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    271\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    272\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mProject was not passed and could not be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    273\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdetermined from the environment.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/cloud/client/__init__.py:287\u001b[0m, in \u001b[0;36m_ClientProjectMixin._determine_default\u001b[0;34m(project)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    285\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_determine_default\u001b[39m(project):\n\u001b[1;32m    286\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Helper:  use default project detection.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m     \u001b[39mreturn\u001b[39;00m _determine_default_project(project)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/cloud/_helpers/__init__.py:152\u001b[0m, in \u001b[0;36m_determine_default_project\u001b[0;34m(project)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Determine default project ID explicitly or implicitly as fall-back.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \n\u001b[1;32m    142\u001b[0m \u001b[39mSee :func:`google.auth.default` for details on how the default project\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[39m:returns: Default project if it can be determined.\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[39mif\u001b[39;00m project \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 152\u001b[0m     _, project \u001b[39m=\u001b[39m google\u001b[39m.\u001b[39;49mauth\u001b[39m.\u001b[39;49mdefault()\n\u001b[1;32m    153\u001b[0m \u001b[39mreturn\u001b[39;00m project\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/auth/_default.py:692\u001b[0m, in \u001b[0;36mdefault\u001b[0;34m(scopes, request, quota_project_id, default_scopes)\u001b[0m\n\u001b[1;32m    684\u001b[0m             _LOGGER\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    685\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mNo project ID could be determined. Consider running \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    686\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m`gcloud config set project` or setting the \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    687\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39menvironment variable\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    688\u001b[0m                 environment_vars\u001b[39m.\u001b[39mPROJECT,\n\u001b[1;32m    689\u001b[0m             )\n\u001b[1;32m    690\u001b[0m         \u001b[39mreturn\u001b[39;00m credentials, effective_project_id\n\u001b[0;32m--> 692\u001b[0m \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mDefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "\u001b[0;31mDefaultCredentialsError\u001b[0m: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from google.cloud import storage\n",
    "\n",
    "def download_parquet_files(links, bucket_name):\n",
    "    # Crea una instancia del cliente de almacenamiento de Google Cloud\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    # Recorre la lista de enlaces para descargar los archivos Parquet\n",
    "    for link in links:\n",
    "        # Obtiene el nombre del archivo Parquet del enlace\n",
    "        filename = link.split('/')[-1]\n",
    "\n",
    "        # Descarga el archivo Parquet\n",
    "        response = requests.get(link)\n",
    "        parquet_content = response.content\n",
    "\n",
    "        # Sube el archivo Parquet al bucket en Google Cloud Storage\n",
    "        bucket = storage_client.get_bucket(bucket_name)\n",
    "        blob = bucket.blob(filename)\n",
    "        blob.upload_from_string(parquet_content, content_type='application/octet-stream')\n",
    "\n",
    "def read_parquet_files_with_schema(links, schema):\n",
    "    # Lista para almacenar los DataFrames\n",
    "    dfs = []\n",
    "\n",
    "    # Recorre la lista de enlaces y procesa cada archivo Parquet\n",
    "    for link in links:\n",
    "        # Obtiene el nombre del archivo Parquet del enlace\n",
    "        filename = link.split('/')[-1]\n",
    "\n",
    "        # Lee el archivo Parquet con el esquema especificado\n",
    "        path = f'gs://web_scraping_trips_0/{filename}'\n",
    "        table = pq.read_table(path, columns=list(schema.keys()))\n",
    "\n",
    "        # Obtener los datos del archivo Parquet según el esquema\n",
    "        data = {}\n",
    "        for attr, attr_schema in schema.items():\n",
    "            column_data = table.column(attr).to_pandas()\n",
    "            if attr_schema['dtype'] is not None:\n",
    "                column_data = column_data.astype(attr_schema['dtype'])\n",
    "                if pd.api.types.is_integer_dtype(attr_schema['dtype']):\n",
    "                    column_data = column_data.replace([np.inf, -np.inf], pd.NA).dropna().astype(attr_schema['dtype'])\n",
    "            data[attr_schema['name']] = column_data\n",
    "\n",
    "        # Crea el DataFrame con los datos del archivo Parquet y el esquema deseado\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        # Agrega el DataFrame a la lista\n",
    "        dfs.append(df)\n",
    "\n",
    "    # Concatena los DataFrames en uno solo\n",
    "    df_concatenated = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    return df_concatenated\n",
    "\n",
    "\n",
    "# Lista de enlaces de archivos Parquet\n",
    "links = [\n",
    "    'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet',\n",
    "    'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet',\n",
    "    'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-03.parquet'\n",
    "]\n",
    "\n",
    "# Esquema deseado para la lectura del archivo Parquet\n",
    "schema = {\n",
    "    'tpep_pickup_datetime': {'name': 'pickup_datetime', 'dtype': 'datetime64[ns]'},\n",
    "    'tpep_dropoff_datetime': {'name': 'dropoff_datetime', 'dtype': 'datetime64[ns]'},\n",
    "    'passenger_count': {'name': 'passenger_count', 'dtype': float},\n",
    "    'trip_distance': {'name': 'distance', 'dtype': float},\n",
    "    'payment_type': {'name': 'payment_type', 'dtype': str},\n",
    "    'PULocationID': {'name': 'pickup_location', 'dtype': float},\n",
    "    'DOLocationID': {'name': 'dropoff_location', 'dtype': float},\n",
    "    'total_amount': {'name': 'total_amount', 'dtype': float},\n",
    "    'tip_amount': {'name': 'tip_amount', 'dtype': float}\n",
    "}\n",
    "\n",
    "# Descarga los archivos Parquet al bucket en Google Cloud Storage\n",
    "bucket_name = 'web_scraping_trips_0'\n",
    "download_parquet_files(links, bucket_name)\n",
    "\n",
    "# Lee los archivos Parquet y crea el DataFrame con el esquema deseado\n",
    "df = read_parquet_files_with_schema(links, schema)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
